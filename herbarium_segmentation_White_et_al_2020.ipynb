{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be loaded by first generating a conda environment using the env_for_fern_segmentaion.txt file. Run the following two lines in a terminal first. You must have conda installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create --name herb_segmentation --file env_for_fern_segmentation.txt\n",
    "# conda activate herb_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: fastai and pytorch are not simple to install. Be prepared to spend some time getting fastai and pytorch in the right configuration according to the env_for_fern_segmentation.txt specifications. This may include downloading older versions of these libraries, as they are in active development and new versions are released frequently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from PIL import Image as image_save\n",
    "import itertools\n",
    "import operator\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.wrn import wrn_22\n",
    "import functools, traceback\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the custom classes and the trained model \"fern_segmentation.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegLabelListCustom(SegmentationLabelList):\n",
    "    def open(self, fn): return open_mask(fn, div=True)\n",
    "    \n",
    "class SegItemListCustom(SegmentationItemList):\n",
    "    _label_cls = SegLabelListCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "pickle_url = 'https://www.dropbox.com/s/rwwesulkcbspkhf/fern_segmentation.pkl?dl=1'\n",
    "if not os.path.exists('fern_segmentation.pkl'):\n",
    "    urlretrieve(pickle_url, 'fern_segmentation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pickle = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_bot = load_learner(path = path_to_pickle,\n",
    "                      file = 'fern_segmentation.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a single image through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = Path(\"examples/example1.jpg\") # MUST CHANGE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(path_img)\n",
    "img_mask_pred = seg_bot.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ImageSegment (1, 256, 256),\n",
       " tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]]),\n",
       " tensor([[[9.9993e-01, 9.9999e-01, 1.0000e+00,  ..., 9.9998e-01,\n",
       "           9.9967e-01, 9.9851e-01],\n",
       "          [9.9998e-01, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "           9.9995e-01, 9.9975e-01],\n",
       "          [9.9999e-01, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "           9.9999e-01, 9.9994e-01],\n",
       "          ...,\n",
       "          [9.9995e-01, 9.9999e-01, 1.0000e+00,  ..., 9.9996e-01,\n",
       "           9.9970e-01, 9.9586e-01],\n",
       "          [9.9940e-01, 9.9984e-01, 1.0000e+00,  ..., 9.9971e-01,\n",
       "           9.9649e-01, 9.6665e-01],\n",
       "          [9.9241e-01, 9.9678e-01, 9.9978e-01,  ..., 9.9446e-01,\n",
       "           9.6365e-01, 8.5454e-01]],\n",
       " \n",
       "         [[7.1575e-05, 1.0269e-05, 1.9280e-06,  ..., 1.9599e-05,\n",
       "           3.3051e-04, 1.4852e-03],\n",
       "          [2.2848e-05, 1.9750e-06, 3.5300e-07,  ..., 4.3603e-06,\n",
       "           5.4616e-05, 2.5016e-04],\n",
       "          [8.5134e-06, 9.3486e-07, 1.2321e-07,  ..., 6.7523e-07,\n",
       "           7.4688e-06, 5.9208e-05],\n",
       "          ...,\n",
       "          [4.8573e-05, 1.0947e-05, 9.7320e-08,  ..., 3.5767e-05,\n",
       "           3.0443e-04, 4.1415e-03],\n",
       "          [5.9987e-04, 1.5750e-04, 2.7728e-06,  ..., 2.9327e-04,\n",
       "           3.5145e-03, 3.3354e-02],\n",
       "          [7.5894e-03, 3.2208e-03, 2.1661e-04,  ..., 5.5353e-03,\n",
       "           3.6345e-02, 1.4546e-01]]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_mask_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a large batch of images through and saving the masked versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = 'examples' # MUST CHANGE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can deactivate this warning by passing `no_check=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/triznam/miniconda3/envs/fern_seg/lib/python3.6/site-packages/fastai/basic_data.py:245: UserWarning: Your training dataloader is empty, you have only 3 items in your training set.\n",
      "                 Your batch size is 64, you should lower it.\n",
      "  Your batch size is {self.train_dl.batch_size}, you should lower it.\"\"\")\n"
     ]
    }
   ],
   "source": [
    "data_test = (ImageList.from_folder(path = path_to_images, \n",
    "                                        extensions = \".jpg\")\n",
    "             .split_none()\n",
    "             .label_empty()).transform(tfms=None, size=256).databunch(bs=64).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64 # could change this is you are having issues with memory\n",
    "seg_bot.data.test_dl = data_test.fix_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_batches = int(len(seg_bot.data.test_ds)/bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_masked_images = \"examples_masked\" # MUST CHANGE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_iter = iter(seg_bot.data.test_dl)\n",
    "test_filenames_iter = iter(seg_bot.data.test_ds.items)\n",
    "test_images_iter = iter(seg_bot.data.test_ds)\n",
    "\n",
    "for n in range(number_of_batches):\n",
    "    batch = next(test_batch_iter)\n",
    "    preds_tup = seg_bot.pred_batch(batch=batch)\n",
    "    pred_masks = np.argmax(preds_tup, axis = 1)\n",
    "    pred_names = array(itertools.islice(test_filenames_iter, bs))\n",
    "    orig_images = array(itertools.islice(test_images_iter, bs))\n",
    "    for z in range(bs):\n",
    "        #print(pred_names[z].parts[-1] + \" being masked and output to masked_\" + pred_names[z].parts[-1])\n",
    "        orig_loaded_img = orig_images[z][0].data\n",
    "        pred_mask = pred_masks[z].unsqueeze(0).double()\n",
    "        masked = orig_loaded_img.cpu().double() * pred_mask\n",
    "        mask2 = masked.data.permute(1, 2, 0)\n",
    "        ndarr = mask2.mul_(255).add_(0.5).clamp_(0, 255).to('cpu', torch.uint8).numpy()\n",
    "        im = image_save.fromarray(ndarr)\n",
    "        im.save(path_to_save_masked_images+\"/masked_\"+pred_names[z].parts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
